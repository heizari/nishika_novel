{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43771c34",
   "metadata": {},
   "source": [
    "## keywordのコサイン類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c5972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = '014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c737388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ginza\n",
    "import spacy\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722077d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeZenkakuSpace(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('　', ' ')\n",
    "    return df\n",
    "\n",
    "def histEachFavs(df, col, height=3, aspect=4, title=''):\n",
    "    '''\n",
    "    FAVごとのカラムの要素のヒストグラム\n",
    "    '''\n",
    "    for fav in sorted(df[FAV].unique()):\n",
    "        sns.catplot(x=col,data=df.query(f\"{FAV} == @fav\"),kind='count',height=height, aspect=aspect)\n",
    "        plt.title(f'{title} fav group:{fav}')\n",
    "        \n",
    "def getQueries(df, cols):\n",
    "    assert type(cols) == str or type(cols) == list, 'cols is str or list'\n",
    "    queries = []\n",
    "    if type(cols) == str:\n",
    "        queries = [f'{cols} == {flag}' for flag in sorted(df[cols].unique())]\n",
    "    elif type(cols) == list:\n",
    "        for col in cols:\n",
    "            col_queries = [f'{col} == {flag}' for flag in sorted(df[col].unique())]\n",
    "            if len(queries) == 0:\n",
    "                queries = col_queries\n",
    "            else:\n",
    "                queries = [f\"{q} & {col_queries[0]}\" for q in queries] + [f'{q} & {col_queries[1]}' for q in queries]\n",
    "            \n",
    "    return queries\n",
    "\n",
    "def columnUnique(df, col):\n",
    "    return sorted(df[col].unique())\n",
    "\n",
    "def histColumnsFavs(df, cols:list, height=3, aspect=6, title=''):\n",
    "    '''\n",
    "    カラムの要素に対するのFAVの数のヒストグラム\n",
    "    colsがlistのときは複数カラムの要素ごと\n",
    "    '''\n",
    "    queries = getQueries(df, cols)\n",
    "    for query in queries:\n",
    "        data = df.query(query)\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        sns.catplot(x=FAV,data=data,kind='count',height=height, aspect=aspect)\n",
    "        plt.title(f'{title} {query}')\n",
    "        \n",
    "def histEachFavsByCategory(df, df_target, col):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    cats = sorted(df[col].unique())\n",
    "    for cat in cats:\n",
    "        fig, axes = plt.subplots(figsize=(30,10), ncols=3, nrows=2)\n",
    "        for ax, fav in zip(axes.ravel(), favs):\n",
    "            target_mask = (df[FAV] == fav) & (df[col] == cat)\n",
    "            ax.hist(df_target.loc[target_mask], bins=100)\n",
    "            ax.set_xlim(-1,df_target.max())\n",
    "            ax.set_title(f'category:{cat}, fav:{fav}, num={target_mask.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9431bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../output'\n",
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "ID = 'ncode'\n",
    "FAV = 'fav_novel_cnt_bin'\n",
    "favs = sorted(train_df[FAV].unique())\n",
    "\n",
    "train_df.userid = train_df.userid.astype('str')\n",
    "train_df.genre = train_df.genre.astype('str')\n",
    "test_df.userid = test_df.userid.astype('str')\n",
    "test_df.genre = test_df.genre.astype('str')\n",
    "str_cols = ['title', 'story', 'keyword', 'writer']\n",
    "train_df = removeZenkakuSpace(train_df, str_cols)\n",
    "test_df = removeZenkakuSpace(test_df, str_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2364acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ncode', 'general_firstup', 'title', 'story', 'keyword', 'userid',\n",
       "       'writer', 'biggenre', 'genre', 'novel_type', 'end', 'isstop', 'isr15',\n",
       "       'isbl', 'isgl', 'iszankoku', 'istensei', 'istenni', 'pc_or_k',\n",
       "       'fav_novel_cnt_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6971ef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fd3ac7287f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=FAV, data=train_df, kind='count', height=3,aspect=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4799f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ginza\n"
     ]
    }
   ],
   "source": [
    "if 'nlp' not in locals():\n",
    "    nlp = spacy.load(\"ja_ginza\")\n",
    "    print('load ginza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661656f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_keyword = ~train_df.keyword.isnull()\n",
    "train_df.keyword = train_df.keyword.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a436dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSequenceVectorizer:\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "        self.tokenizer = BertJapaneseTokenizer.from_pretrained(self.model_name)\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(self.model_name)\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.max_len = 128\n",
    "            \n",
    "\n",
    "    def vectorize(self, sentence : str) -> np.array:\n",
    "        inp = self.tokenizer.encode(sentence)\n",
    "        len_inp = len(inp)\n",
    "\n",
    "        if len_inp >= self.max_len:\n",
    "            inputs = inp[:self.max_len]\n",
    "            masks = [1] * self.max_len\n",
    "        else:\n",
    "            inputs = inp + [0] * (self.max_len - len_inp)\n",
    "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
    "\n",
    "        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n",
    "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
    "        \n",
    "        seq_out = self.bert_model(inputs_tensor, masks_tensor)[0]\n",
    "        pooled_out = self.bert_model(inputs_tensor, masks_tensor)[1]\n",
    "\n",
    "        if torch.cuda.is_available():    \n",
    "            return seq_out[0][0].cpu().detach().numpy() # 0番目は [CLS] token, 768 dim の文章特徴量\n",
    "        else:\n",
    "            return seq_out[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46157eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySpacyToKeyword(keywords):\n",
    "    return np.vectorize(lambda keyword: nlp(str(keyword)))(keywords)\n",
    "\n",
    "def applySpacyToRow(row):\n",
    "    keywords = row.split()\n",
    "    global pbar\n",
    "    pbar.update(1)\n",
    "    return BSV.vectorize(keywords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa6c53ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-e112954aff94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword_vectorize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplySpacyToRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-6152b7688345>\u001b[0m in \u001b[0;36mapplySpacyToRow\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapplySpacyToRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "train_df[:3].loc[mask_no_keyword]['keyword_vectorize'] = applySpacyToRow(train_df[:3].loc[mask_no_keyword].keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a02a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BSV = BertSequenceVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdbdd5dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e112954aff94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword_vectorize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplySpacyToRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-6d2f7ec42083>\u001b[0m in \u001b[0;36mapplySpacyToRow\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapplySpacyToRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplySpacyToKeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "train_df[:3].loc[mask_no_keyword]['keyword_vectorize'] = applySpacyToRow(train_df[:3].loc[mask_no_keyword].keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4922ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:3].loc[mask_no_keyword]['vectorize'] = np.vectorize(lambda x : BSV.vectorize(x))(train_df[:3].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c24fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3944/37774 [01:05<09:21, 60.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2a7ef826000a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords_vectrize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplySpacyToRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_no_keyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2106\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                       for a in args]\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-6152b7688345>\u001b[0m in \u001b[0;36mapplySpacyToRow\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBSV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6069334644a8>\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmasks_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mseq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mpooled_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         )\n\u001b[0;32m--> 991\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     ):\n\u001b[0;32m--> 401\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tqdm(total=sum(mask_no_keyword)) as pbar:\n",
    "    train_df.loc[mask_no_keyword]['keywords_vectrize'] = np.vectorize(applySpacyToRow)(train_df.loc[mask_no_keyword]['keyword'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96c31fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['keywords'] = train_df.keyword.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b83e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1290c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梅田浩志\n",
      "402\n",
      "    ncode writer\n",
      "0  N7588B   梅田浩志\n",
      "1  N8726B     ルト\n",
      "梅田浩志\n",
      "402\n",
      "    ncode writer\n",
      "0  N7588B   梅田浩志\n",
      "1  N8726B     ルト\n",
      "ルト\n",
      "401\n",
      "    ncode writer\n",
      "0  N7588B   梅田浩志\n",
      "1  N8726B     ルト\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([None, None], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(test, excluded='b')(a=train_df[:2]['writer'], c=train_df[:2]['genre'],b=train_df[:2][['ncode','writer']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
